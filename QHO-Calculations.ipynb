{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running on cpu\n",
      "Training with 10000 samples...\n",
      "nodft\n",
      "Noisy labels\n",
      "Clean X_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/Desktop/kuramoto-sivashinsky-solver/utils.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(arr).float().requires_grad_(g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0*X2 {X2, X0}\n",
      "X1 {X1}\n",
      "Constructing -1.0*V*hf*(0.002839 + 0.998631*I) - 1.0*h_xx*(0.000211 - 0.499448*I) {V, h_xx, hf}\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import torch\n",
    "from torch.autograd import grad, Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from scipy import io\n",
    "from utils import *\n",
    "from preprocess import *\n",
    "from models import *\n",
    "\n",
    "# Let's do facy optimizers\n",
    "from madgrad import MADGRAD\n",
    "from lbfgsnew import LBFGSNew\n",
    "\n",
    "# Tracking\n",
    "from tqdm import trange\n",
    "\n",
    "import sympy\n",
    "import sympytorch\n",
    "\n",
    "\n",
    "# torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You're running on\", device)\n",
    "\n",
    "DATA_PATH = './data/harmonic_osc.mat'\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "xlimit = 512\n",
    "tlimit = 161\n",
    "\n",
    "x = data['x'][0][:xlimit]\n",
    "t = data['t'][:,0][:tlimit]\n",
    "\n",
    "spatial_dim = x.shape[0]\n",
    "time_dim = t.shape[0]\n",
    "\n",
    "potential = np.vstack([0.5*np.power(x,2).reshape((1,spatial_dim)) for _ in range(time_dim)])\n",
    "X, T = np.meshgrid(x, t)\n",
    "Exact = data['usol'][:tlimit, :xlimit]\n",
    "\n",
    "def fn(e): return e.flatten()[:, None]\n",
    "\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "# Converting in a feature vector for each feature\n",
    "X_star = np.hstack((fn(X), fn(T)))\n",
    "h_star = fn(Exact)\n",
    "potential = fn(potential)\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(axis=0)\n",
    "ub = X_star.max(axis=0)\n",
    "\n",
    "N = 10000 # N = X_star.shape[0] \n",
    "N = min(N, X_star.shape[0])\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "print(\"Training with\", N, \"samples...\")\n",
    "\n",
    "lb = to_tensor(lb, False).to(device)\n",
    "ub = to_tensor(ub, False).to(device)\n",
    "\n",
    "X_train = X_star[idx, :]\n",
    "h_train = h_star[idx, :]\n",
    "u_train = np.real(h_train)\n",
    "v_train = np.imag(h_train)\n",
    "V = potential[idx, :]\n",
    "\n",
    "# adding noise\n",
    "denoise = False\n",
    "if denoise:\n",
    "    modelname = \"dft\"\n",
    "else:\n",
    "    modelname = \"nodft\"\n",
    "print(modelname)\n",
    "noise_intensity = 0.01/np.sqrt(2)\n",
    "noisy_xt = False; noisy_labels = True\n",
    "if noisy_labels:\n",
    "    u_train = perturb(u_train, noise_intensity)\n",
    "    v_train = perturb(v_train, noise_intensity)\n",
    "    h_train = u_train+1j*v_train\n",
    "    # h_train = \n",
    "    print(\"Noisy labels\")\n",
    "else: print(\"Clean labels\")\n",
    "if noisy_xt:\n",
    "    X_train = perturb2d(X_train, noise_intensity)\n",
    "    print(\"Noisy (x, t)\")\n",
    "else: print(\"Clean X_train\")\n",
    "\n",
    "# Converting to tensor\n",
    "X_star = to_tensor(X_star, True)\n",
    "h_star = to_complex_tensor(h_star, False)\n",
    "X_train = to_tensor(X_train, True)\n",
    "u_train = to_tensor(u_train, False)\n",
    "v_train = to_tensor(v_train, False)\n",
    "h_train = torch.tensor(h_train, dtype=torch.cfloat, requires_grad=False)\n",
    "V = to_tensor(V, False).to(device)\n",
    "\n",
    "feature_names = ['hf', 'h_xx', 'V']\n",
    "\n",
    "noise_x, x_fft, x_PSD = fft1d_denoise(to_tensor(X_train[:, 0:1]), c=-0.05, return_real=True)\n",
    "noise_x = X_train[:, 0:1] - noise_x\n",
    "noise_t, t_fft, t_PSD = fft1d_denoise(to_tensor(X_train[:, 1:2]), c=-0.05, return_real=True)\n",
    "noise_t = X_train[:, 1:2] - noise_t\n",
    "X_train_S = cat(noise_x, noise_t)\n",
    "\n",
    "h_train_S, h_train_fft, h_train_PSD = fft1d_denoise(h_train, c=-0.05, return_real=False)\n",
    "h_train_S = h_train - h_train_S\n",
    "\n",
    "del noise_x, noise_t\n",
    "\n",
    "# 1st stage results\n",
    "# clean all\n",
    "# PDE derived using STRidge\n",
    "# u_t = (-0.000337 +0.497526i)h_xx\n",
    "#     + (-0.001670 -0.997429i)hf V\n",
    "# 161x512\n",
    "# u_t = (-0.000722 +0.499001)h_xx\n",
    "#     + (-0.002967 -1.000228i)hf V\n",
    "# noisy1\n",
    "# PDE derived using STRidge\n",
    "# u_t = (0.000702 +0.495803i)h_xx\n",
    "#     + (0.000641 -0.994030i)hf V\n",
    "# noisy2\n",
    "# PDE derived using STRidge\n",
    "# u_t = (-0.001146 +0.487772i)h_xx\n",
    "#     + (-0.001516 -0.989395i)hf V\n",
    "\n",
    "mode = int(noisy_xt)+int(noisy_labels)\n",
    "\n",
    "if mode == 0:\n",
    "    cn1 = (-0.002272 -0.999772*1j)\n",
    "    cn2 = (-0.000547 +0.499581*1j)\n",
    "    name = \"cleanall\"\n",
    "elif mode == 1:\n",
    "    cn1 = (-0.002839 -0.998631*1j)\n",
    "    cn2 = (-0.000211+0.499448*1j)\n",
    "    name = \"noisy1\"\n",
    "elif mode == 2:\n",
    "    cn1 = (-0.002149 -0.996097*1j)\n",
    "    cn2 = (-0.000531 +0.497700*1j)\n",
    "    name = \"noisy2\"\n",
    "    \n",
    "cns = [cn1, cn2]\n",
    "\n",
    "# Type the equation got from the symbolic regression step\n",
    "# No need to save the eq save a pickle file before\n",
    "program1 = \"X0*X2\"\n",
    "pde_expr1, variables1 = build_exp(program1); print(pde_expr1, variables1)\n",
    "\n",
    "program2 = \"X1\"\n",
    "pde_expr2, variables2 = build_exp(program2); print(pde_expr2, variables2)\n",
    "\n",
    "mod = ComplexSymPyModule(expressions=[pde_expr1, pde_expr2], complex_coeffs=cns); mod.train()\n",
    "\n",
    "class PDEExpression(nn.Module):\n",
    "    def __init__(self, terms, values, symbolic_module=True):\n",
    "        super(PDEExpression, self).__init__()\n",
    "        self.terms = terms\n",
    "        self.values = [complex(e) for e in values]\n",
    "        self.diff_dict = dict(zip(self.terms, self.values))\n",
    "        self.string_expression = '+'.join([str(v)+'*'+str(k) for k, v in self.diff_dict.items()])\n",
    "        pde_expr, self.variables = build_exp(self.string_expression)\n",
    "        print(\"Constructing\", pde_expr, self.variables)\n",
    "        self.pde_expr = None\n",
    "        if symbolic_module:\n",
    "            self.pde_expr = sympytorch.SymPyModule(expressions=[pde_expr])\n",
    "            \n",
    "    # Computing the approx u_t\n",
    "    def forward(self, e): return self.pde_expr(e)\n",
    "    # Get a coeff\n",
    "    def get_coeff(self, t): return self.diff_dict[t]\n",
    "\n",
    "mod = PDEExpression([\"hf*V\", \"h_xx\"], cns, False)\n",
    "\n",
    "class ComplexPINN(nn.Module):\n",
    "    def __init__(self, model, loss_fn, index2features, scale=False, lb=None, ub=None, init_cs=(0.01, 0.01), init_betas=(0.0, 0.0)):\n",
    "        super(ComplexPINN, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        # Setting the parameters up\n",
    "        self.initial_param0 = loss_fn.get_coeff(\"hf*V\")\n",
    "        self.initial_param1 = loss_fn.get_coeff(\"h_xx\")\n",
    "        self.param0_real = nn.Parameter(torch.FloatTensor([self.initial_param0.real]))\n",
    "        self.param0_imag = nn.Parameter(torch.FloatTensor([self.initial_param0.imag]))\n",
    "        self.param1_real = nn.Parameter(torch.FloatTensor([self.initial_param1.real]))\n",
    "        self.param1_imag = nn.Parameter(torch.FloatTensor([self.initial_param1.imag]))\n",
    "        \n",
    "        global N\n",
    "        # self.in_fft_nn = FFTTh(c=init_cs[0], func=lambda x: (torch.exp(-F.relu(x))))\n",
    "        # self.out_fft_nn = FFTTh(c=init_cs[1], func=lambda x: (torch.exp(-F.relu(x))))\n",
    "        self.in_fft_nn = FFTTh(c=init_cs[0])\n",
    "        self.out_fft_nn = FFTTh(c=init_cs[1])\n",
    "        # Beta-Robust PCA\n",
    "        self.inp_rpca = RobustPCANN(beta=init_betas[0], is_beta_trainable=True, inp_dims=2, hidden_dims=32)\n",
    "        self.out_rpca = RobustPCANN(beta=init_betas[1], is_beta_trainable=True, inp_dims=2, hidden_dims=32)\n",
    "        \n",
    "        self.index2features = index2features; self.feature2index = {}\n",
    "        for idx, fn in enumerate(self.index2features): self.feature2index[fn] = str(idx)\n",
    "        \n",
    "        self.scale = scale; self.lb, self.ub = lb, ub\n",
    "        if self.scale and (self.lb is None or self.ub is None): \n",
    "            print(\"Please provide thw lower and upper bounds of your PDE.\")\n",
    "            print(\"Otherwise, there will be error(s)\")\n",
    "        \n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        H = torch.cat([x, t], dim=1)\n",
    "        if self.scale: H = self.neural_net_scale(H)\n",
    "        return self.model(H)\n",
    "    \n",
    "    def loss(self, X_input, X_input_S, y_input, y_input_S, update_pde_params=True, pure_imag=False, denoise=False):\n",
    "        total_loss = []\n",
    "        \n",
    "        if denoise:\n",
    "            # Denoising FFT on (x, t)\n",
    "            X_input_S = cat(torch.fft.ifft(self.in_fft_nn(X_input_S[1])*X_input_S[0]).real.reshape(-1, 1), \n",
    "                     torch.fft.ifft(self.in_fft_nn(X_input_S[3])*X_input_S[2]).real.reshape(-1, 1))\n",
    "            X_input_S = X_input - X_input_S\n",
    "            X_input = self.inp_rpca(X_input, X_input_S, normalize=True)\n",
    "\n",
    "            # Denoising FFT on y_input\n",
    "            y_input_S = y_input-torch.fft.ifft(self.out_fft_nn(y_input_S[1])*y_input_S[0]).reshape(-1, 1)\n",
    "            y_input = self.out_rpca(cat(y_input.real, y_input.imag), \n",
    "                                    cat(y_input_S.real, y_input_S.imag), \n",
    "                                    normalize=True)\n",
    "            y_input = torch.complex(y_input[:, 0:1], y_input[:, 1:2])\n",
    "        \n",
    "        # Compute losses\n",
    "        grads_dict, u_t = self.grads_dict(X_input[:, 0:1], X_input[:, 1:2])\n",
    "        X0 = cplx2tensor(grads_dict['X0'])\n",
    "        \n",
    "        # MSE Loss\n",
    "        total_loss.append(complex_mse(X0, y_input))\n",
    "            \n",
    "        # PDE Loss\n",
    "        param0 = torch.complex(self.param0_real, self.param0_imag)\n",
    "        param1 = torch.complex(self.param1_real, self.param1_imag)\n",
    "        if not update_pde_params: param0, param1 = param0.detach(), param1.detach()\n",
    "        u_t_pred = (param0*X0*grads_dict['X2'])+(param1*grads_dict['X1'])\n",
    "        total_loss.append(complex_mse(u_t_pred, u_t))\n",
    "        \n",
    "        if pure_imag:\n",
    "            total_loss.append(torch.linalg.norm(param0.real, 1)+torch.linalg.norm(param1.real, 1))\n",
    "            \n",
    "        return total_loss\n",
    "    \n",
    "    def grads_dict(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        u_t = complex_diff(uf, t, device)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # Without calling grad\n",
    "        derivatives = {}\n",
    "        derivatives['X0'] = uf\n",
    "        derivatives['X1'] = complex_diff(complex_diff(uf, x, device), x, device)\n",
    "        derivatives['X2'] = 0.5*torch.pow(x, 2)\n",
    "        \n",
    "        return derivatives, u_t\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))\n",
    "\n",
    "    def neural_net_scale(self, inp): \n",
    "        return 2*(inp-self.lb)/(self.ub-self.lb)-1\n",
    "\n",
    "inp_dimension = 2\n",
    "act = CplxToCplx[torch.tanh]\n",
    "complex_model = CplxSequential(\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 1, bias=True),\n",
    "                            )\n",
    "\n",
    "complex_model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(inp_dimension, 200),\n",
    "                                    RealToCplx(),\n",
    "                                    complex_model\n",
    "                                    )\n",
    "\n",
    "\n",
    "# Pretrained model\n",
    "if mode == 2:\n",
    "    semisup_model_state_dict = cpu_load(\"./qho_weights/jointtrained_noisy2_semisup_model_lambda1_0.03.pth\")\n",
    "elif mode == 1:\n",
    "    semisup_model_state_dict = cpu_load(\"./qho_weights/jointtrained_noisy1_semisup_model_lambda1_0.03.pth\")\n",
    "elif mode == 0:\n",
    "    semisup_model_state_dict = cpu_load(\"./qho_weights/jointtrained_semisup_model_lambda1_0.03_work.pth\")\n",
    "\n",
    "parameters = OrderedDict()\n",
    "# Filter only the parts that I care about renaming (to be similar to what defined in TorchMLP).\n",
    "inner_part = \"network.model.\"\n",
    "for p in semisup_model_state_dict:\n",
    "    if inner_part in p:\n",
    "        parameters[p.replace(inner_part, \"\")] = semisup_model_state_dict[p]\n",
    "complex_model.load_state_dict(parameters)\n",
    "\n",
    "pinn = ComplexPINN(model=complex_model, loss_fn=mod, index2features=feature_names, \n",
    "                   scale=True, lb=lb, ub=ub).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_coeffcient_error(sig, ground):\n",
    "    # This function is for testing a single effective coefficient.\n",
    "    return 100*np.abs(sig-ground)/np.abs(ground)\n",
    "\n",
    "def cabs(e): return torch.sqrt(e.real**2 + e.imag**2)\n",
    "\n",
    "# def percent_coeffcient_error(sig, ground):\n",
    "#     # This function is for testing a single effective coefficient.\n",
    "#     return 100*complex_l1_norm((sig-ground))/complex_l1_norm(ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With dft\n",
      "Loaded the model's weights properly\n",
      "(0.00011437786452006549-0.9992526173591614j)\n",
      "(3.0384351703105494e-05+0.5000637769699097j)\n",
      "0.0449 0.0307\n",
      "Rel l2 err: 0.0035665624\n",
      "Loaded the model's weights properly\n",
      "(1.0002991984947585e-05-0.9989632368087769j)\n",
      "(3.821068094111979e-05+0.5001750588417053j)\n",
      "0.0698 0.0339\n",
      "Rel l2 err: 0.004662585\n",
      "Loaded the model's weights properly\n",
      "(0.00023310448159463704-0.9989814758300781j)\n",
      "(0.0002457057998981327+0.5000653862953186j)\n",
      "0.0777 0.0268\n",
      "Rel l2 err: 0.0062372773\n"
     ]
    }
   ],
   "source": [
    "dft_weights = [\"./qho_weights/cleanall_161x512_dft_pinn_learned.pth\", \n",
    "               \"./qho_weights/noisy1_161x512_dft_pinn_learned.pth\", \n",
    "               \"./qho_weights/noisy2_161x512_dft_pinn_learned.pth\"]\n",
    "print(\"With dft\")\n",
    "for wei in dft_weights:\n",
    "    pinn = load_weights(pinn, wei)\n",
    "    est1 = pinn.param0_real.detach().item()+1j*pinn.param0_imag.detach().item()\n",
    "    est2 = pinn.param1_real.detach().item()+1j*pinn.param1_imag.detach().item()\n",
    "    print(est1)\n",
    "    print(est2)\n",
    "    err = np.array([percent_coeffcient_error(est1, -1j), \n",
    "                percent_coeffcient_error(est2, 0.5*1j)])\n",
    "    print(format(err.mean(), '.4f'), format(err.std(), '.4f'))\n",
    "    print(\"Rel l2 err:\", relative_l2_error(to_numpy(cabs(pinn(*dimension_slicing(X_star)))), to_numpy(cabs(h_star))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dft\n",
      "Loaded the model's weights properly\n",
      "(0.00011855408956762403-0.999647855758667j)\n",
      "(4.562547474051826e-05+0.49998557567596436j)\n",
      "0.0234 0.0138\n",
      "Loaded the model's weights properly\n",
      "(-0.00044186218292452395-0.9994983673095703j)\n",
      "(3.2680745789548382e-06+0.5000836253166199j)\n",
      "0.0418 0.0251\n",
      "Loaded the model's weights properly\n",
      "(0.0017959531396627426-0.9981059432029724j)\n",
      "(0.000855024962220341+0.4999435245990753j)\n",
      "0.2162 0.0448\n"
     ]
    }
   ],
   "source": [
    "dft_weights = [\"./qho_weights/cleanall_161x512_nodft_pinn_learned.pth\", \n",
    "               \"./qho_weights/noisy1_161x512_nodft_pinn_learned.pth\", \n",
    "               \"./qho_weights/noisy2_161x512_nodft_pinn_learned.pth\"]\n",
    "print(\"Without dft\")\n",
    "for wei in dft_weights:\n",
    "    pinn = load_weights(pinn, wei)\n",
    "    est1 = pinn.param0_real.detach().item()+1j*pinn.param0_imag.detach().item()\n",
    "    est2 = pinn.param1_real.detach().item()+1j*pinn.param1_imag.detach().item()\n",
    "    print(est1)\n",
    "    print(est2)\n",
    "    err = np.array([percent_coeffcient_error(est1, -1j), \n",
    "                percent_coeffcient_error(est2, 0.5*1j)])\n",
    "    print(format(err.mean(), '.4f'), format(err.std(), '.4f'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
